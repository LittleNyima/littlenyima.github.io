<!DOCTYPE html><html lang="zh-TW" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>極東晝寢愛好家 - 晝寢日和(@w@)zzz</title><meta name="author" content="LittleNyima"><meta name="copyright" content="LittleNyima"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="極東晝寢愛好家">
<meta property="og:url" content="https://littlenyima.github.io/page/2/index.html">
<meta property="og:site_name" content="極東晝寢愛好家">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://littlenyima.github.io/img/avatar.jpg">
<meta property="article:author" content="LittleNyima">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://littlenyima.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon64x64.png"><link rel="canonical" href="https://littlenyima.github.io/page/2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '複製成功',
    error: '複製錯誤',
    noSupport: '瀏覽器不支援'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '剛剛',
    min: '分鐘前',
    hour: '小時前',
    day: '天前',
    month: '個月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '載入更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '極東晝寢愛好家',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-09-06 14:05:58'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="極東晝寢愛好家" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">41</div></a><a href="/tags/"><div class="headline">標籤</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分類</div><div class="length-num">4</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 歸檔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-train-subway"></i><span> 開往</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/top_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="極東晝寢愛好家"><span class="site-name">極東晝寢愛好家</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 歸檔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-train-subway"></i><span> 開往</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">極東晝寢愛好家</h1><div id="site_social_icons"><a class="social-icon" href="https://www.linkedin.com/in/leyan-zhu-323abb26a/" target="_blank" title="领英"><i class="fa-brands fa-linkedin"></i></a><a class="social-icon" href="https://www.zhihu.com/people/littlenyima/" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="https://www.cnblogs.com/littlenyima/" target="_blank" title="博客园"><i class="fa-solid fa-blog"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fa-solid fa-rss"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/47-cogvideo-text-to-video-generation/" title="笔记｜扩散模型（一五）CogVideo 论文解读｜文生视频大模型">笔记｜扩散模型（一五）CogVideo 论文解读｜文生视频大模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-09-10T03:02:41.000Z" title="發表於 2024-09-10 11:02:41">2024-09-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：CogVideo:
Large-scale Pretraining for Text-to-Video Generation via
Transformers
官方实现：THUDM/CogVideo（由于目前的仓库里，CogVideo
相关的代码已经被替换为 CogVideoX 的代码，所以如果希望浏览 CogVideo
的代码，包含该方法代码最后一个 commit 为 5f914b7，也就是
这个链接）

和本系列中的 DALL-E 一样，虽然 CogVideo
也并非基于扩散模型的方法，但由于其后续工作 CogVideoX
是基于扩散模型的，所以这篇文章也放到扩散模型系列里。

CogVideo 是基于大规模预训练 Transformer
进行视频生成的工作，也是近期推出的 CogVideoX
的前身。相比于文生图任务，文生视频的主要难点在于两个方面：首先是数据更加稀缺，视频-文本配对数据比较少；其次是视频多了时序信息。
本模型基于文生图模型 CogView2 进行训练，在训练时使用了 5.4 M
视频-文本对数据。在训练时，文本条件是通过 in context
lea ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/35-textual-inversion-personalize-generation/" title="笔记｜扩散模型（一四）Textual Inversion 理论与实现">笔记｜扩散模型（一四）Textual Inversion 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-07T09:51:27.000Z" title="發表於 2024-08-07 17:51:27">2024-08-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：An Image is
Worth One Word: Personalizing Text-to-Image Generation using Textual
Inversion
官方实现：rinongal/textual_inversion
非官方实现：huggingface/diffusers

Textual Inversion 也是对 diffusion model
进行微调的主要范式之一，从标题中 An Image is Worth One Word
可以猜测，这个方法也是类似 Dreambooth 用某个特别的 text token
来表示所要生成的物体。不过和 Dreambooth 不同的是，Textual Inversion
并不是在 prompt
中插入某个修饰词来表示主体或者风格，而是直接将主体学习为一个
token。这个方法比较特别的是它并不改变原始模型的权重，而只学习了一个额外的
embedding。
Textual Inversion
现有的工作已经证明了 diffusion model 的 text embedding
空间对图像的语义信息有一 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/32-dit-scalable-diffusion-with-transformers/" title="笔记｜扩散模型（一三）DiT｜Diffusion with Transformer">笔记｜扩散模型（一三）DiT｜Diffusion with Transformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-05T10:12:49.000Z" title="發表於 2024-08-05 18:12:49">2024-08-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Scalable
Diffusion Models with Transformers
官方实现：facebookresearch/DiT

Transformer
在许多领域都有很不错的表现，尤其是近期大语言模型的成功证明了 scaling law
在 NLP 领域的效果。Diffusion Transformer（DiT）把 transformer
架构引入了扩散模型中，并且试图用同样的 scaling
方法提升扩散模型的效果。DiT 提出后就受到了很多后续工作的
follow，例如比较有名的视频生成方法 sora 就采取了 DiT
作为扩散模型的架构。
Diffusion Transformer
在正式开始介绍 DiT 之前，需要先了解一下 DiT 使用的扩散模型架构。DiT
使用的是 latent diffusion，VAE 采用和 Stable Diffusion 相同的
KL-f8，并且使用了 Improved DDPM（详细介绍见这个链接），同时预测噪声的均值和方差。

Patchify
由于 DiT 使用了 latent diffusion，对于 \(256 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/29-uvit-a-vit-backbone-for-diffusion-models/" title="笔记｜扩散模型（一二）U-ViT｜Diffusion with Transformer">笔记｜扩散模型（一二）U-ViT｜Diffusion with Transformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-04T13:35:56.000Z" title="發表於 2024-08-04 21:35:56">2024-08-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：All are
Worth Words: A ViT Backbone for Diffusion Models
官方实现：baofff/U-ViT

扩散模型自从被提出后，主干网络一直都是各种基于卷积的 UNet
的变体。而在其他领域，Transformer 架构则更加流行，尤其是由于 Transformer
多模态性能和缩放能力都很强，因此把 Transformer
架构用于扩散模型是很值得尝试的。这篇 U-ViT
的工作就是一个不错的尝试。
U-ViT 的设计
在开始具体的介绍之前，可以先看一下 U-ViT
整体的架构。可以看出其有几个主要的特点：

所有的元素，包括 latent、timestep、condition 等都以 token
的形式进行了 embedding；
类似于 UNet，在不同的 Transformer Block
层之间添加了长跳跃连接。

虽然理论上来说这两个点都比较简单，但作者进行了一系列实验来选择比较好的设计。

长跳跃连接的实现
将主分支和长跳跃连接分支的特征分别记为 \(h_m\) 和 \(h_s\)。作者选取了几种不同的实现方式进行 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/27-sdxl-stable-diffusion-xl/" title="笔记｜扩散模型（一一）Stable Diffusion XL 理论与实现">笔记｜扩散模型（一一）Stable Diffusion XL 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-02T07:45:21.000Z" title="發表於 2024-08-02 15:45:21">2024-08-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：SDXL:
Improving Latent Diffusion Models for High-Resolution Image
Synthesis
官方实现：Stability-AI/generative-models
非官方实现：huggingface/diffusers

Stable Diffusion XL (SDXL) 是 Stablility AI 对 Stable Diffusion
进行改进的工作，主要通过一些工程化的手段提高了 SD 模型的生成能力。相比于
Stable Diffusion，SDXL
对模型架构、条件注入、训练策略等都进行了优化，并且还引入了一个额外的
refiner，用于对生成图像进行超分，得到高分辨率图像。
Stable Diffusion XL
模型架构改进
SDXL 对模型的 VAE、UNet 和 text encoder
都进行了改进，下面依次介绍一下。
VAE
相比于 Stable Diffusion，SDXL 对 VAE
模型进行了重新训练，训练时使用了更大的 batchsize（256，Stable Diffusion
 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/25-lora-low-rank-adaptation/" title="笔记｜LoRA 理论与实现｜大模型轻量级微调">笔记｜LoRA 理论与实现｜大模型轻量级微调</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-01T09:54:37.000Z" title="發表於 2024-08-01 17:54:37">2024-08-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：LoRA:
Low-Rank Adaptation of Large Language Models
官方实现：microsoft/LoRA
非官方实现：huggingface/peft、huggingface/diffusers

这篇文章要介绍的是一种大模型/扩散模型的微调方法，叫做低秩适应（也就是
Low-Rank Adaptation，LoRA）。经常使用 stable diffusion webui
的读者应该对这个名词非常熟悉，通过给扩散模型加载不同的
lora，可以让扩散模型生成出不同风格的图像。现在也已经有很多平台（例如 civitai、tensorart 等）可以下载现成的
lora，可以看出 LoRA 的影响力还是比较大的。
LoRA 作为一种高效的参数微调（Parameter-Efficient
Fine-Tuning，PEFT）方法，最初是被用来微调 LLM
的，后来也被用来微调扩散模型。这种方法的主要思想是固定住预训练模型的参数，同时引入额外的可训练低秩分解模块，只训练额外引入的这部分参数，从而大大减小模型的微调成本。
与其他的 Peft 方法相比 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/24-dreambooth-subject-driven-generation/" title="笔记｜扩散模型（一〇）Dreambooth 理论与实现｜主题驱动生成">笔记｜扩散模型（一〇）Dreambooth 理论与实现｜主题驱动生成</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-01T06:56:59.000Z" title="發表於 2024-08-01 14:56:59">2024-08-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：DreamBooth:
Fine Tuning Text-to-Image Diffusion Models for Subject-Driven
Generation
项目主页：https://dreambooth.github.io/
非官方实现：huggingface/diffusers、XavierXiao/Dreambooth-Stable-Diffusion

时隔快两周继续更新一下 AIGC
系列的学习笔记，这篇文章算是比较火的一个工作，而且很多 AI
照相馆应用的背后也是这个算法。这一算法关注的任务是主题驱动生成，也就是给定某个特定物体（或者某个人或动物）的几张图像对模型进行微调，微调后就能生成该主题在各种场景、姿态下的图像。具体效果如下图所示，给出几张柯基的照片对模型进行微调，模型就能生成这只小狗的各种图像。

Dreambooth
Dreambooth
这个方法使用的依然是基础的文生图扩散模型，不过对这类模型进行了「个性化」。具体来说就是用给出的几张图像以及设计好的
prompt 对原始模型进行微调。微调的主要目的是把要生成的目标植入到输出
domain ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/23-imagen-t2i-with-deep-language-understanding/" title="笔记｜扩散模型（九）Imagen 理论与实现">笔记｜扩散模型（九）Imagen 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-20T07:08:55.000Z" title="發表於 2024-07-20 15:08:55">2024-07-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Photorealistic Text-to-Image
Diffusion Models with Deep Language Understanding
非官方实现：lucidrains/imagen-pytorch

Imagen 是 Google Research 的文生图工作，这个工作并没有沿用 Stable
Diffusion 的架构，而是级联了一系列普通的 DDPM
模型。其主要的贡献有以下几个方面：

使用比较大的文本模型进行文本嵌入，可以获得比使用 CLIP
更好的文本理解能力；
在采样阶段引入了一种动态阈值的方法，可以利用更高的 guidance scale
来生成更真实、细节更丰富的图像（这里的阈值是控制 \(\mathbf{x}\) 的范围）；
改良了 UNet，提出 Efficient
UNet，使模型更简单、收敛更快、内存消耗更少。

该模型的架构如下图所示，可以看到使用了一个条件生成的 diffusion
模型以及两个超分辨率模型，每个模型都以文本模型的 embedding
作为条件，先生成一个 64 分辨率的图像，然后逐步超分辨率到 1024 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/22-dalle-2-hierarchical-text-to-image-generation/" title="笔记｜扩散模型（八）DALL-E 2 (unCLIP) 理论与实现">笔记｜扩散模型（八）DALL-E 2 (unCLIP) 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-18T17:30:15.000Z" title="發表於 2024-07-19 01:30:15">2024-07-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Hierarchical
Text-Conditional Image Generation with CLIP Latents
非官方实现：lucidrains/DALLE2-pytorch

DALL-E 2 是一个比较经典的文生图模型，虽然和 Stable Diffusion
的架构有些区别，但是也利用了 CLIP
的文本-图像对齐能力实现了用文本作为条件进行图像生成。由于 CLIP
是输入文本和图像获得相应的特征，而 DALL-E 2
是将输入的文本转化为特征再转换为图像，相当于把 CLIP
中的图像编码器反转了过来，所以这个方法也被称为
unCLIP。这个模型主要由三个部分组成：

CLIP 模型：负责将条件文本转换到文本-图像的统一特征空间中；
prior 模型：将文本特征转换为图像特征，用于后续的图像生成；
decoer 模型：将从 prior
获得的图像特征转换为具体的生成图像，相当于反转了 CLIP 中的图像
encoder。

模型的架构图如下图所示，虚线的上方是 CLIP 模型，下方是 prior 和
decoder 模型。

DALL-E 2 的训练 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/21-latent-diffusion-models/" title="笔记｜扩散模型（七）Latent Diffusion Models（Stable Diffusion）理论与实现">笔记｜扩散模型（七）Latent Diffusion Models（Stable Diffusion）理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-16T08:18:25.000Z" title="發表於 2024-07-16 16:18:25">2024-07-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：High-Resolution Image Synthesis
with Latent Diffusion Models
官方实现：CompVis/latent-diffusion、CompVis/stable-diffusion

这一篇文章的内容是 Latent Diffusion Models（LDM），也就是大名鼎鼎的
Stable
Diffusion。先前的扩散模型一直面临的比较大的问题是采样空间太大，学习的噪声维度和图像的维度是相同的。当进行高分辨率图像生成时，需要的计算资源会急剧增加，虽然
DDIM 等工作已经对此有所改善，但效果依然有限。Stable Diffusion
的方法非常巧妙，其把扩散过程转换到了低维度的隐空间中，解决了这个问题。
方法介绍
本方法的整体结构如下图所示，主要分为三部分：最左侧的红框对应于感知图像压缩，中间的绿框对应
Latent Diffusion
Models，右侧的白框表示生成条件，下面将分别介绍这三个部分。

感知图像压缩
LDM
把图像生成过程从原始的图像像素空间转换到了一个隐空间，具体来说，对于一个维度为
\(\mathb ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/#content-inner">5</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">LittleNyima</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">41</div></a><a href="/tags/"><div class="headline">標籤</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分類</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/LittleNyima"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://www.linkedin.com/in/leyan-zhu-323abb26a/" target="_blank" title="领英"><i class="fa-brands fa-linkedin"></i></a><a class="social-icon" href="https://www.zhihu.com/people/littlenyima/" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="https://www.cnblogs.com/littlenyima/" target="_blank" title="博客园"><i class="fa-solid fa-blog"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fa-solid fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到 LittleNyima 的栖息地~（偶尔出没）</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/57-zero-redundancy-optimizer/" title="笔记｜大模型训练（四）Zero Redundancy Optimizer (ZeRO)">笔记｜大模型训练（四）Zero Redundancy Optimizer (ZeRO)</a><time datetime="2025-09-05T09:01:12.000Z" title="發表於 2025-09-05 17:01:12">2025-09-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/56-ultrascale-playbook-data-parallelism/" title="笔记｜大模型训练（三）数据并行与相关优化策略">笔记｜大模型训练（三）数据并行与相关优化策略</a><time datetime="2025-09-02T06:37:45.000Z" title="發表於 2025-09-02 14:37:45">2025-09-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/55-ultrascale-playbook-parallel-programming/" title="笔记｜大模型训练（二）并行编程快速入门">笔记｜大模型训练（二）并行编程快速入门</a><time datetime="2025-08-31T16:00:57.000Z" title="發表於 2025-09-01 00:00:57">2025-09-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/54-ultrascale-playbook-training-llms-on-one-gpu/" title="笔记｜大模型训练（一）单卡训练的分析与优化策略">笔记｜大模型训练（一）单卡训练的分析与优化策略</a><time datetime="2025-08-29T15:55:32.000Z" title="發表於 2025-08-29 23:55:32">2025-08-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/53-issue-ssl-certificates-with-certbot/" title="技术相关｜使用 Certbot 为通配符域名签发 SSL 证书">技术相关｜使用 Certbot 为通配符域名签发 SSL 证书</a><time datetime="2025-05-26T09:57:41.000Z" title="發表於 2025-05-26 17:57:41">2025-05-26</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分類</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Jottings/"><span class="card-category-list-name">Jottings</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Notes/"><span class="card-category-list-name">Notes</span><span class="card-category-list-count">27</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Techniques/"><span class="card-category-list-name">Techniques</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Tutorials/"><span class="card-category-list-name">Tutorials</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>標籤</span></div><div class="card-tag-cloud"><a href="/tags/Normalizing-flow/" style="font-size: 1.1em; color: #999">Normalizing flow</a> <a href="/tags/Generavie-models/" style="font-size: 1.1em; color: #999">Generavie models</a> <a href="/tags/Generative-models/" style="font-size: 1.43em; color: #99a6b9">Generative models</a> <a href="/tags/Animation-engine/" style="font-size: 1.1em; color: #999">Animation engine</a> <a href="/tags/Hexo/" style="font-size: 1.1em; color: #999">Hexo</a> <a href="/tags/Pytorch/" style="font-size: 1.17em; color: #999c9f">Pytorch</a> <a href="/tags/Diffusion-models/" style="font-size: 1.37em; color: #99a4b2">Diffusion models</a> <a href="/tags/Distributed-Computing/" style="font-size: 1.1em; color: #999">Distributed Computing</a> <a href="/tags/SSL/" style="font-size: 1.1em; color: #999">SSL</a> <a href="/tags/Deep-learning/" style="font-size: 1.5em; color: #99a9bf">Deep learning</a> <a href="/tags/Github-Actions/" style="font-size: 1.1em; color: #999">Github Actions</a> <a href="/tags/Music-theory/" style="font-size: 1.1em; color: #999">Music theory</a> <a href="/tags/Python/" style="font-size: 1.1em; color: #999">Python</a> <a href="/tags/Manimgl/" style="font-size: 1.1em; color: #999">Manimgl</a> <a href="/tags/Certbot/" style="font-size: 1.1em; color: #999">Certbot</a> <a href="/tags/Security/" style="font-size: 1.1em; color: #999">Security</a> <a href="/tags/Genetative-models/" style="font-size: 1.1em; color: #999">Genetative models</a> <a href="/tags/Linux/" style="font-size: 1.23em; color: #999ea6">Linux</a> <a href="/tags/Writing/" style="font-size: 1.1em; color: #999">Writing</a> <a href="/tags/Large-language-models/" style="font-size: 1.3em; color: #99a1ac">Large language models</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>歸檔</span><a class="card-more-btn" href="/archives/" title="檢視更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/09/"><span class="card-archive-list-date">九月 2025</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/08/"><span class="card-archive-list-date">八月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/05/"><span class="card-archive-list-date">五月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">9</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>網站資訊</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章數目 :</div><div class="item-count">41</div></div><div class="webinfo-item"><div class="item-name">本站訪客數 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站總訪問量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最後更新時間 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-09-06T06:05:57.967Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/top_img.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By LittleNyima</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主題 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">网站封面图作者<a target="_blank" rel="noopener" href="https://www.pixiv.net/artworks/41045442">よこ。</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="淺色和深色模式轉換"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="單欄和雙欄切換"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="設定"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="返回頂部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>