<!DOCTYPE html><html lang="zh-TW" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>極東晝寢愛好家 - 晝寢日和(@w@)zzz</title><meta name="author" content="LittleNyima"><meta name="copyright" content="LittleNyima"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="極東晝寢愛好家">
<meta property="og:url" content="https://littlenyima.github.io/page/2/index.html">
<meta property="og:site_name" content="極東晝寢愛好家">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://littlenyima.github.io/img/avatar.jpg">
<meta property="article:author" content="LittleNyima">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://littlenyima.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon64x64.png"><link rel="canonical" href="https://littlenyima.github.io/page/2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '複製成功',
    error: '複製錯誤',
    noSupport: '瀏覽器不支援'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '剛剛',
    min: '分鐘前',
    hour: '小時前',
    day: '天前',
    month: '個月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '載入更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '極東晝寢愛好家',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-08-29 18:41:04'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="極東晝寢愛好家" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">標籤</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分類</div><div class="length-num">4</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 歸檔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-train-subway"></i><span> 開往</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/top_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="極東晝寢愛好家"><span class="site-name">極東晝寢愛好家</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 歸檔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-train-subway"></i><span> 開往</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">極東晝寢愛好家</h1><div id="site_social_icons"><a class="social-icon" href="https://www.linkedin.com/in/leyan-zhu-323abb26a/" target="_blank" title="领英"><i class="fa-brands fa-linkedin"></i></a><a class="social-icon" href="https://www.zhihu.com/people/littlenyima/" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="https://www.cnblogs.com/littlenyima/" target="_blank" title="博客园"><i class="fa-solid fa-blog"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fa-solid fa-rss"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/27-sdxl-stable-diffusion-xl/" title="笔记｜扩散模型（一一）Stable Diffusion XL 理论与实现">笔记｜扩散模型（一一）Stable Diffusion XL 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-02T07:45:21.000Z" title="發表於 2024-08-02 15:45:21">2024-08-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：SDXL:
Improving Latent Diffusion Models for High-Resolution Image
Synthesis
官方实现：Stability-AI/generative-models
非官方实现：huggingface/diffusers

Stable Diffusion XL (SDXL) 是 Stablility AI 对 Stable Diffusion
进行改进的工作，主要通过一些工程化的手段提高了 SD 模型的生成能力。相比于
Stable Diffusion，SDXL
对模型架构、条件注入、训练策略等都进行了优化，并且还引入了一个额外的
refiner，用于对生成图像进行超分，得到高分辨率图像。
Stable Diffusion XL
模型架构改进
SDXL 对模型的 VAE、UNet 和 text encoder
都进行了改进，下面依次介绍一下。
VAE
相比于 Stable Diffusion，SDXL 对 VAE
模型进行了重新训练，训练时使用了更大的 batchsize（256，Stable Diffusion
 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/25-lora-low-rank-adaptation/" title="笔记｜LoRA 理论与实现｜大模型轻量级微调">笔记｜LoRA 理论与实现｜大模型轻量级微调</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-01T09:54:37.000Z" title="發表於 2024-08-01 17:54:37">2024-08-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：LoRA:
Low-Rank Adaptation of Large Language Models
官方实现：microsoft/LoRA
非官方实现：huggingface/peft、huggingface/diffusers

这篇文章要介绍的是一种大模型/扩散模型的微调方法，叫做低秩适应（也就是
Low-Rank Adaptation，LoRA）。经常使用 stable diffusion webui
的读者应该对这个名词非常熟悉，通过给扩散模型加载不同的
lora，可以让扩散模型生成出不同风格的图像。现在也已经有很多平台（例如 civitai、tensorart 等）可以下载现成的
lora，可以看出 LoRA 的影响力还是比较大的。
LoRA 作为一种高效的参数微调（Parameter-Efficient
Fine-Tuning，PEFT）方法，最初是被用来微调 LLM
的，后来也被用来微调扩散模型。这种方法的主要思想是固定住预训练模型的参数，同时引入额外的可训练低秩分解模块，只训练额外引入的这部分参数，从而大大减小模型的微调成本。
与其他的 Peft 方法相比 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/24-dreambooth-subject-driven-generation/" title="笔记｜扩散模型（一〇）Dreambooth 理论与实现｜主题驱动生成">笔记｜扩散模型（一〇）Dreambooth 理论与实现｜主题驱动生成</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-08-01T06:56:59.000Z" title="發表於 2024-08-01 14:56:59">2024-08-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：DreamBooth:
Fine Tuning Text-to-Image Diffusion Models for Subject-Driven
Generation
项目主页：https://dreambooth.github.io/
非官方实现：huggingface/diffusers、XavierXiao/Dreambooth-Stable-Diffusion

时隔快两周继续更新一下 AIGC
系列的学习笔记，这篇文章算是比较火的一个工作，而且很多 AI
照相馆应用的背后也是这个算法。这一算法关注的任务是主题驱动生成，也就是给定某个特定物体（或者某个人或动物）的几张图像对模型进行微调，微调后就能生成该主题在各种场景、姿态下的图像。具体效果如下图所示，给出几张柯基的照片对模型进行微调，模型就能生成这只小狗的各种图像。

Dreambooth
Dreambooth
这个方法使用的依然是基础的文生图扩散模型，不过对这类模型进行了「个性化」。具体来说就是用给出的几张图像以及设计好的
prompt 对原始模型进行微调。微调的主要目的是把要生成的目标植入到输出
domain ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/23-imagen-t2i-with-deep-language-understanding/" title="笔记｜扩散模型（九）Imagen 理论与实现">笔记｜扩散模型（九）Imagen 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-20T07:08:55.000Z" title="發表於 2024-07-20 15:08:55">2024-07-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Photorealistic Text-to-Image
Diffusion Models with Deep Language Understanding
非官方实现：lucidrains/imagen-pytorch

Imagen 是 Google Research 的文生图工作，这个工作并没有沿用 Stable
Diffusion 的架构，而是级联了一系列普通的 DDPM
模型。其主要的贡献有以下几个方面：

使用比较大的文本模型进行文本嵌入，可以获得比使用 CLIP
更好的文本理解能力；
在采样阶段引入了一种动态阈值的方法，可以利用更高的 guidance scale
来生成更真实、细节更丰富的图像（这里的阈值是控制 \(\mathbf{x}\) 的范围）；
改良了 UNet，提出 Efficient
UNet，使模型更简单、收敛更快、内存消耗更少。

该模型的架构如下图所示，可以看到使用了一个条件生成的 diffusion
模型以及两个超分辨率模型，每个模型都以文本模型的 embedding
作为条件，先生成一个 64 分辨率的图像，然后逐步超分辨率到 1024 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/22-dalle-2-hierarchical-text-to-image-generation/" title="笔记｜扩散模型（八）DALL-E 2 (unCLIP) 理论与实现">笔记｜扩散模型（八）DALL-E 2 (unCLIP) 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-18T17:30:15.000Z" title="發表於 2024-07-19 01:30:15">2024-07-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Hierarchical
Text-Conditional Image Generation with CLIP Latents
非官方实现：lucidrains/DALLE2-pytorch

DALL-E 2 是一个比较经典的文生图模型，虽然和 Stable Diffusion
的架构有些区别，但是也利用了 CLIP
的文本-图像对齐能力实现了用文本作为条件进行图像生成。由于 CLIP
是输入文本和图像获得相应的特征，而 DALL-E 2
是将输入的文本转化为特征再转换为图像，相当于把 CLIP
中的图像编码器反转了过来，所以这个方法也被称为
unCLIP。这个模型主要由三个部分组成：

CLIP 模型：负责将条件文本转换到文本-图像的统一特征空间中；
prior 模型：将文本特征转换为图像特征，用于后续的图像生成；
decoer 模型：将从 prior
获得的图像特征转换为具体的生成图像，相当于反转了 CLIP 中的图像
encoder。

模型的架构图如下图所示，虚线的上方是 CLIP 模型，下方是 prior 和
decoder 模型。

DALL-E 2 的训练 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/21-latent-diffusion-models/" title="笔记｜扩散模型（七）Latent Diffusion Models（Stable Diffusion）理论与实现">笔记｜扩散模型（七）Latent Diffusion Models（Stable Diffusion）理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-16T08:18:25.000Z" title="發表於 2024-07-16 16:18:25">2024-07-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：High-Resolution Image Synthesis
with Latent Diffusion Models
官方实现：CompVis/latent-diffusion、CompVis/stable-diffusion

这一篇文章的内容是 Latent Diffusion Models（LDM），也就是大名鼎鼎的
Stable
Diffusion。先前的扩散模型一直面临的比较大的问题是采样空间太大，学习的噪声维度和图像的维度是相同的。当进行高分辨率图像生成时，需要的计算资源会急剧增加，虽然
DDIM 等工作已经对此有所改善，但效果依然有限。Stable Diffusion
的方法非常巧妙，其把扩散过程转换到了低维度的隐空间中，解决了这个问题。
方法介绍
本方法的整体结构如下图所示，主要分为三部分：最左侧的红框对应于感知图像压缩，中间的绿框对应
Latent Diffusion
Models，右侧的白框表示生成条件，下面将分别介绍这三个部分。

感知图像压缩
LDM
把图像生成过程从原始的图像像素空间转换到了一个隐空间，具体来说，对于一个维度为
\(\mathb ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/20-dalle-zero-shot-text-to-image-generation/" title="笔记｜扩散模型（六）DALL-E 理论与实现｜自回归文生图">笔记｜扩散模型（六）DALL-E 理论与实现｜自回归文生图</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-14T08:48:41.000Z" title="發表於 2024-07-14 16:48:41">2024-07-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Zero-Shot
Text-to-Image Generation
官方实现：openai/DALL-E
非官方实现：kuprel/min-dalle、lucidrains/DALLE-pytorch

虽然 DALL-E 并不是基于扩散模型的方法，但是因为它的后续工作 DALL-E 2
和 DALL-E 3 都是基于扩散模型的，所以这个方法也放到扩散模型系列里。

DALL-E 是 OpenAI
比较早期的文生图模型，和一些早期的多模态方法的做法类似，其主要的思想是将图像的
token 和文本的 token 当作同一个序列输入
Transformer，利用自回归生成能力进行图像生成。除了使用 Transformer
进行生成之外，由于图像的像素数量相比文本 token
来说过多，因此需要将图像也预先进行 tokenization，这里使用的模型是
VQ-VAE（也就是 dVAE）；为了优先输出生成质量比较高的结果，这里使用 CLIP
对结果的质量进行了排序。总结来说，DALL-E 共包括三个部分：

Transformer：用来进行自回归生成；
VQ-VAE：将图像 t ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/19-classifier-free-guidance-for-diffusion-models/" title="笔记｜扩散模型（五）Classifier-Free Guidance 理论与实现">笔记｜扩散模型（五）Classifier-Free Guidance 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-12T08:27:55.000Z" title="發表於 2024-07-12 16:27:55">2024-07-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Classifier-Free Diffusion
Guidance

上一篇文章我们学习了 Classifier
Guidance，这种方法通过引入一个额外的分类器，使用梯度引导的方式成功地实现了条件生成。虽然
Classifier Guidance 可以直接复用训练好的 diffusion
models，不过这种方法的问题是很明显的，首先需要额外训练一个分类器，而且这个分类器不仅仅分类一般的图像，还需要分类加噪后的图像，这会给方法带来比较大的额外开销；其次分类器训练完成后类别就固定下来了，如果希望生成新的类别就需要重新训练分类器。这篇文章学习的
Classifier-Free Guidance 则可以比较好地解决这些问题。
Classifier-Free Guidance
在 Classifier Guidance 中，从条件概率 \(p(\mathbf{x}_t|y)\) 出发，利用贝叶斯公式和
score function
推导出了以下公式，在下面的公式中，等号右侧的第一项已知，第二项则需要引入分类器进行计算。
\[
\nabla_{\mathbf{x}_t}\lo ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/18-classifier-guidance-for-diffusion-models/" title="笔记｜扩散模型（四）Classifier Guidance 理论与实现">笔记｜扩散模型（四）Classifier Guidance 理论与实现</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-10T09:40:51.000Z" title="發表於 2024-07-10 17:40:51">2024-07-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">
论文链接：Diffusion
Models Beat GANs on Image Synthesis

在前边的几篇文章中我们已经学习了 DDPM
以及分别对其训练和采样过程进行改进的工作，不过这些方法都只能进行无条件生成，而无法对生成过程进行控制。我们这次学习的不再是无条件生成，而是通过一定方式对生成过程进行控制，比较常见的有两种：Classifier
Guidance 与 Classifier-Free Guidance，本文首先介绍第一种。
一些工作背景
实际上 Classifier Guidance 是上边给出的论文工作中的一部分，虽然
Improved DDPM 已经比较有效地提升了 DDPM
的生成效果，但在一些大数据集上的效果仍然不如当时主流的生成模型 GAN。因此
OpenAI 在 Improved DDPM
的基础上继续进行了一些改进，主要是一些工程上的改进：

在模型的尺寸基本不变的前提下，提升模型的深度与宽度之比，相当于使用更深的模型；
增加多头注意力中 head 的数量；
使用多分辨率 attention，即 32x32、16x16 和 8x8，而不是只在 1 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/17-score-based-modeling-with-sde/" title="笔记｜Score-based Generative Models（二）基于 SDE 的模型">笔记｜Score-based Generative Models（二）基于 SDE 的模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">發表於</span><time datetime="2024-07-05T08:37:40.000Z" title="發表於 2024-07-05 16:37:40">2024-07-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Notes/">Notes</a></span></div><div class="content">上一篇文章中我们介绍了 score-based model
的基本概念，包括其如何对分布进行建模、如何从建模的分布中进行采样以及通过对分布进行扰动提高其建模精度的方式。在这篇文章中我们将介绍的是如何使用随机微分方程（也就是
SDE）进行 score-based 建模。
随机微分方程简介
首先我们先介绍一些随机微分方程的基本知识以便理解。
我们首先举一个常微分方程（ODE）的例子，例如下面的一个常微分方程： \[
\frac{\mathrm{d}\mathbf{x}}{\mathrm{d}t}=\mathbf{f}(\mathbf{x},t)\quad\mathrm{or}\quad\mathrm{d}\mathbf{x}=\mathbf{f}(\mathbf{x},t)\mathrm{d}t
\] 其中的 \(\mathbf{f}(\mathbf{x},t)\) 是一个关于 \(\mathbf{x}\) 和 \(t\) 的函数，其描述了 \(\mathrm{x}\)
随时间的变化趋势，如下面图中的左图所示。直观地说，\(\mathbf{f}(\mathbf{x},t)\)
对应于图中的 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="page-number" href="/page/4/#content-inner">4</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">LittleNyima</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">標籤</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分類</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/LittleNyima"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://www.linkedin.com/in/leyan-zhu-323abb26a/" target="_blank" title="领英"><i class="fa-brands fa-linkedin"></i></a><a class="social-icon" href="https://www.zhihu.com/people/littlenyima/" target="_blank" title="知乎"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="https://www.cnblogs.com/littlenyima/" target="_blank" title="博客园"><i class="fa-solid fa-blog"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fa-solid fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到 LittleNyima 的栖息地~（偶尔出没）</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/53-issue-ssl-certificates-with-certbot/" title="技术相关｜使用 Certbot 为通配符域名签发 SSL 证书">技术相关｜使用 Certbot 为通配符域名签发 SSL 证书</a><time datetime="2025-05-26T09:57:41.000Z" title="發表於 2025-05-26 17:57:41">2025-05-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/52-ddim-inversion-for-cogvideox/" title="开发记录｜基于 CogVideoX 实现 DDIM Inversion">开发记录｜基于 CogVideoX 实现 DDIM Inversion</a><time datetime="2025-02-20T11:44:30.000Z" title="發表於 2025-02-20 19:44:30">2025-02-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/51-flow-matching-for-diffusion-models/" title="笔记｜扩散模型（一八）Flow Matching 理论详解">笔记｜扩散模型（一八）Flow Matching 理论详解</a><time datetime="2024-09-20T03:16:52.000Z" title="發表於 2024-09-20 11:16:52">2024-09-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/50-velocity-prediction-in-diffusion-models/" title="笔记｜扩散模型（一七）扩散模型中的 Velocity Prediction">笔记｜扩散模型（一七）扩散模型中的 Velocity Prediction</a><time datetime="2024-09-19T08:19:41.000Z" title="發表於 2024-09-19 16:19:41">2024-09-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/48-cogvideox-text-to-video-diffusion-models/" title="笔记｜扩散模型（一六）CogVideoX 论文解读｜文生视频扩散模型">笔记｜扩散模型（一六）CogVideoX 论文解读｜文生视频扩散模型</a><time datetime="2024-09-11T02:18:52.000Z" title="發表於 2024-09-11 10:18:52">2024-09-11</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分類</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Jottings/"><span class="card-category-list-name">Jottings</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Notes/"><span class="card-category-list-name">Notes</span><span class="card-category-list-count">23</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Techniques/"><span class="card-category-list-name">Techniques</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Tutorials/"><span class="card-category-list-name">Tutorials</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>標籤</span></div><div class="card-tag-cloud"><a href="/tags/Hexo/" style="font-size: 1.1em; color: #999">Hexo</a> <a href="/tags/Generavie-models/" style="font-size: 1.1em; color: #999">Generavie models</a> <a href="/tags/Python/" style="font-size: 1.1em; color: #999">Python</a> <a href="/tags/Github-Actions/" style="font-size: 1.1em; color: #999">Github Actions</a> <a href="/tags/SSL/" style="font-size: 1.1em; color: #999">SSL</a> <a href="/tags/Diffusion-models/" style="font-size: 1.34em; color: #99a3b0">Diffusion models</a> <a href="/tags/Normalizing-flow/" style="font-size: 1.1em; color: #999">Normalizing flow</a> <a href="/tags/Music-theory/" style="font-size: 1.1em; color: #999">Music theory</a> <a href="/tags/Generative-models/" style="font-size: 1.42em; color: #99a6b7">Generative models</a> <a href="/tags/Deep-learning/" style="font-size: 1.5em; color: #99a9bf">Deep learning</a> <a href="/tags/Pytorch/" style="font-size: 1.18em; color: #999ca1">Pytorch</a> <a href="/tags/Certbot/" style="font-size: 1.1em; color: #999">Certbot</a> <a href="/tags/Animation-engine/" style="font-size: 1.1em; color: #999">Animation engine</a> <a href="/tags/Genetative-models/" style="font-size: 1.1em; color: #999">Genetative models</a> <a href="/tags/Manimgl/" style="font-size: 1.1em; color: #999">Manimgl</a> <a href="/tags/Distributed-Computing/" style="font-size: 1.1em; color: #999">Distributed Computing</a> <a href="/tags/Linux/" style="font-size: 1.26em; color: #999fa8">Linux</a> <a href="/tags/Security/" style="font-size: 1.1em; color: #999">Security</a> <a href="/tags/Writing/" style="font-size: 1.1em; color: #999">Writing</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>歸檔</span><a class="card-more-btn" href="/archives/" title="檢視更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/05/"><span class="card-archive-list-date">五月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">9</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>網站資訊</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章數目 :</div><div class="item-count">37</div></div><div class="webinfo-item"><div class="item-name">本站訪客數 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站總訪問量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最後更新時間 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-08-29T10:41:04.107Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/top_img.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By LittleNyima</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主題 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">网站封面图作者<a target="_blank" rel="noopener" href="https://www.pixiv.net/artworks/41045442">よこ。</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="淺色和深色模式轉換"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="單欄和雙欄切換"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="設定"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="返回頂部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>